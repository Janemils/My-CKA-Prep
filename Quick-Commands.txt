1. To output the yaml of a pod to a file:
kubectl run nginx --image=nginx --dry-run=client -o yaml > pod-template.yaml

2. Difference between replication controller and replication set:
Replication Controller can manage only the pods created within the RC and is a legacy feature.
Replication Set can manage even the existing pods using selectors.

3. To edit a live object:
kubectl edit rs/frontend

4. To scale up or down the number of replicas:
kubectl scale --replicas=4 rs/frontend

5. To rollout to a newer version with a change cause:
k set image deployment/nginx nginx:1.23.4

6. Rollout history and to rollback:
k rollout history deploy/nginx
k rollout undo deploy/nginx --to-revision=1
To populate the change-cause section: kubectl annotate deployment/nginx-deployment kubernetes.io/change-cause="image updated to 1.16.1"

7. Exec into a pod:
 k exec -it deploy-nm1-7d84fc98d5-d74hl -n nm-1 -- sh
 
8. Create a service and expose a deployment to the service the imperative way.
k expose deploy/deploy-nm1 --name=svc-nm1 -n nm-1 --port=80

9. FQDN [Fully Qualified Domain Name}:
curl svc-nm2.nm2.svc.cluster.local
[<service-name>.<namespace>.svc.cluster.local]

10. Cron Job syntax:
[Minute (0-59)] [Hour (0-23)] [Day of Month (1-31)] [Month (1-12)]  [Day of week (0{sun}-6{sat})]

To run a build every 5 minutes:
*/5 * * * *

11. All the static pod manifest files in /etc/kubernetes/manifests path.

12. To go inside the docker container (Node) for kind cluster:
docker exec -it <container-name> bash 

13. To label a node: 
k label node cka-cluster-worker gpu="true"

14. To remove the label of a node:
k label node cka-cluster-worker gpu-

15. To taint a node:
k taint node cka-cluster-worker gpu=true:NoSchedule

16.To remove the taint on a node:
k taint node cka-cluster-worker gpu=true:NoSchedule-

17. To check for where the kubelet is looking for creating the static pods, i.e static pod path, ssh into the worker node or the node where kubelet is up and running.
Look for the config.yaml [Mostly in /var/lib/kubelet/config.yaml in the newer kubernetes versions.] and look out for the field 'staticPodPath'.

18.Difference between emtrypoint, command and arg in dockerfile and manifests:
- If you do not supply commands and args for a container,  the default defined in docker images are used.
- If you supply only args for a container, the default ENTRYPOINT defined in the docker image is run with the args that you supplied.
- If you supply a command for a container, only the supplied command is used. The default ENTRYPOINT and CMD defined in the docker image are ignored and the command is run with the args supplied (or no args if none supplied).

19. Creating config maps and secrets the imperative way:
  
  # Create a new config map named my-config with key1=config1 and key2=config2
  kubectl create configmap <config-map-name> --from-literal=key1=value2 --from-literal=key2=value2
   
  # Create a new config map named my-config from the key=value pairs in the file
  kubectl create configmap my-config --from-env-file=path/to/bar
  Ex: k create cm config-maps3 --from-env-file=/path-to-directory/config-maps-value.txt
  
  config-maps-value.txt

  HOUSE_NAME=Apollo
  GEL_NAME=Aloe
  
  # Create a new secret named my-secret with key1=supersecret and key2=topsecret
  kubectl create secret generic my-secret --from-literal=key1=supersecret --from-literal=key2=topsecret
  
  # Create a new secret named my-secret using a combination of a file and a literal
  kubectl create secret generic my-secret --from-file=ssh-privatekey=path/to/id_rsa
  
  
20. To read the secret out of the ETCD:
	ETCDCTL_API=3 etcdctl    --cacert=/etc/kubernetes/pki/etcd/ca.crt      --cert=/etc/kubernetes/pki/etcd/server.crt    --key=/etc/kubernetes/pki/etcd/server.key     get /registry/secrets/default/secrets2

21. Health Probes:
-> Liveness Probe: Monitors the application and restarts it if it fails.
-> Readiness Probe: Ensures that your application is ready before serving traffic to it.
-> Startup Probe: For Slow/legacy apps where the startup takes a lot of time for the app to be ready.

22. Horizontal Autoscaling:
-> Pre-Requisite: Must have metrics-server pod up and running.
-> Create a deployment and service. The deployment must have requests and limits specified.
-> Create a horizontal pod autoscaler for the deployment:
kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10
-> Wait till the CPU percentage is read.
kubectl get hpa php-apache --watch
-> Once CPU percentage is read to 0~1%, run the command that will generate some load onto the application:
kubectl run -i --tty load-generator --rm --image=busybox:1.28 --restart=Never -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://php-apache; done"
-> Now run the watch command again to observe if the pods get created automatically as soon as the CPU% crosses the threshold.
-> Similarly stop the command and see, if it deletes the pod automatically, once the CPU% is below the threshold.

